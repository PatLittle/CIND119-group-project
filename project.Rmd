---
title: "CIND119 - Group Project"
date: "10/04/2021"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidymodels)
library(vip)
library(rpart.plot)
library(DataExplorer)
library(tictoc)
library(data.table)
```

## Memebers

Patrick Litte, patrick.little@ryerson.ca <br>
Manjola Chiappetta, m1chiappetta@ryerson.ca

## Summary

This section is a summary of the project. 

instructions: 
Write an abstract (a kind of a summary) to describe your project. The abstract must be within 175 to 250 words (inclusive). To write the abstract, first state the problem you are addressing. For example, if your project is on Churn analysis, then give a brief explanation of it. Second, write the summary of your classification results (e.g., accuracy). Third, state key points about the post-predictive analysis and fourth, summarize your recommendations to the organization. 


## Workload Distribution

| Member Name        | List of Tasks Preformed |
|--------------------|-------------------------|
| Patrick Little     | - some tasks            |
| Manjola Chiappetta | - some tasks            |

## Exploratory Data Analysis

In this section we will:
  - Look at the attribute types in the dataset
  - Find and missing values
  - Find max,min,mean and standard deviation of the atttributes
  - Determine any outlier values for the attributes under consideration
  - Analyze the distribution of numeric attributes

```{r}
bank<-read.csv("https://raw.githubusercontent.com/PatLittle/CIND119-group-project/main/bank_marketing/bank.csv")

introduce(bank)
plot_intro(bank)
plot_missing(bank)
#plot_bar(bank, by = "y")
plot_histogram(bank)

plot_correlation(na.omit(bank), type = "d")

plot_prcomp(bank, variance_cap = 0.9, ncol =1L, nrow=1L)

str(bank)
colSums(is.na(bank))
```

## Predictive Modeling / Classification

### Decision Tree

```{r}

###Decision Tree



bank_clean<- bank %>% mutate_if(is.character, factor)

set.seed(888)
bank_split <- initial_split(bank_clean, prop = 0.75, 
                             strata = y)

bank_training <- bank_split %>% training()
bank_test <- bank_split %>% testing()
bank_folds <- vfold_cv(bank_training, v = 10)



bank_recipe <- recipe(y ~ ., data = bank_training) 
 


bank_clean_baked<-bank_recipe %>% 
  prep() %>% 
  bake(new_data = bank_training)

tree_model <- decision_tree(cost_complexity = tune(),
                            tree_depth = tune(),
                            min_n = tune()) %>% 
  set_engine('rpart') %>% 
  set_mode('classification')

tree_workflow <- workflow() %>% 
  add_model(tree_model) %>% 
  add_recipe(bank_recipe)

tree_grid <- grid_latin_hypercube(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          size = 60)

set.seed(888)

tree_tuning <- tree_workflow %>% 
  tune_grid(resamples = bank_folds,
            grid = tree_grid)

tree_tuning %>% show_best('roc_auc')

best_tree <- tree_tuning %>% 
  select_best(metric = 'roc_auc')


final_tree_workflow <- tree_workflow %>% 
  finalize_workflow(best_tree)


tree_wf_fit <- final_tree_workflow %>% 
  fit(data = bank_training)

tree_fit <- tree_wf_fit %>% 
  pull_workflow_fit()

vip(tree_fit)

rpart.plot(tree_fit$fit, roundint = FALSE)

tree_last_fit <- final_tree_workflow %>% 
  last_fit(bank_split)

tree_last_fit %>% collect_metrics()


tree_last_fit %>% collect_predictions() %>% 
  roc_curve(truth  = y, estimate = .pred_no) %>% 
  autoplot()

tree_predictions <- tree_last_fit %>% collect_predictions()

conf_mat(tree_predictions, truth = y, estimate = .pred_class)

predict(tree_last_fit$.workflow[[1]],bank_test[15,])

saveRDS(tree_last_fit$.workflow[[1]],"./saved_model.Rds")

trained_model<-readRDS("saved_model.Rds")

```
### Naive Bayes

```{r}



set.seed(888)
nb_split <- initial_split(bank_clean, prop = 0.75, 
                            strata = y)

nb_training <- nb_split %>% training()
nb_test <- nb_split %>% testing()
nb_folds <- vfold_cv(nb_training, v = 10)

nb_recipe <- recipe(y ~ ., data = nb_training)
  


nb_wf <- workflow() %>%
  add_recipe(nb_recipe)

library(discrim)
nb_spec <- naive_Bayes() %>%
  set_mode("classification") %>%
  set_engine("naivebayes")

nb_spec

nb_fit <- nb_wf %>%
  add_model(nb_spec) %>%
  fit(data = nb_training)

nb_wf_final <-  workflow() %>%
  add_recipe(nb_recipe) %>%
  add_model(nb_spec)

nb_rs <- fit_resamples(
  nb_wf_final,
  nb_folds,
  control = control_resamples(save_pred = TRUE)
)


nb_last_fit <- nb_wf_final %>% 
  last_fit(nb_split)

nb_last_fit %>% collect_metrics()

nb_last_fit %>% collect_predictions() %>% 
  roc_curve(truth  = y, estimate = .pred_no) %>% 
  autoplot()

nb_predictions <- nb_last_fit %>% collect_predictions()
conf_mat(nb_predictions, truth = y, estimate = .pred_class)



```
## XGBoost

```{r}

as.data.table(bank_clean)

set.seed(888)
xg_split<- initial_split(bank_clean)
xg_train<-training(xg_split)
xg_test<-testing(xg_split)

set.seed(888)
xg_folds<-vfold_cv(xg_train,v=10)

xgb_spec <- boost_tree(
  trees = 1000, 
  tree_depth = tune(), min_n = tune(), 
  loss_reduction = tune(),                     
  sample_size = tune(), mtry = tune(),         
  learn_rate = tune()                        
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

xgb_spec

xgb_grid <- grid_latin_hypercube(
  tree_depth(),
  min_n(),
  loss_reduction(),
  sample_size = sample_prop(),
  finalize(mtry(), xg_train),
  learn_rate(),
  size = 60
)

xgb_grid

xgb_recipe <- recipe(y ~ ., data = xg_train) %>%
  step_dummy(all_nominal(), -all_outcomes())
  


tic()
xgb_recipe %>%
  prep() %>%
  bake(new_data = xg_train) 
toc()


xgb_wf <- workflow() %>%
  add_model(xgb_spec) %>%
  add_recipe(xgb_recipe)

xgb_wf


library(doParallel)
cores<-detectCores()
cl<- makeCluster(cores[1]-4)
registerDoParallel(cl)

tic()
set.seed(888)
xgb_res <- tune_grid(
  xgb_wf,
  resamples = xg_folds,
  grid = xgb_grid,
  control = control_grid(save_pred = TRUE))
toc()

best_auc <- select_best(xgb_res, "roc_auc")
best_auc


final_xgb <- finalize_workflow(
  xgb_wf,
  best_auc
)

tic()
final_res <- last_fit(final_xgb, xg_split)
collect_metrics(final_res)
toc()

final_res %>%
  collect_predictions() %>%
  roc_curve(y, .pred_no) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_line(size = 1.5, color = "midnightblue") +
  geom_abline(
    lty = 2, alpha = 0.5,
    color = "gray50",
    size = 1.2
  )


final_res %>%
  collect_predictions() %>% 
  conf_mat(truth = y, estimate = .pred_class)

library(vip)
final_xgb %>%
  fit(data = xg_train) %>%
  pull_workflow_fit() %>%
  vip(geom = "point")

final_res %>% collect_metrics()
```


## Conclusions and Recommendations

Some text wrapping up the report